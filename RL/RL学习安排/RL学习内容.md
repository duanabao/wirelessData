# RL进度安排

参考： [强化学习导论](./reading/reinforcement learning introduction.pdf)、[神经网络和深度学习 第14章](./reading/神经网络与深度学习.pdf)

## 强化学习基础

1. 多臂赌博机问题（第二章、14.1）

1. 马尔可夫决策过程（第三章、14.1.2—14.1.5）

   RL基本要素和概念、MDP描述、目标函数和值函数的表示

2. 动态规划算法（第四章、14.2.1）

   策略迭代、值迭代、贝尔曼方程

3. 蒙特卡洛方法（第五章、14.2.2）

4. 时序差分方法（第六章、14.2.3）

5. 比较

   model-based和model-free、on-policy和off-policy

## 基于值函数的强化学习

1. Q-learning（六、6，14.2.3.1）

2. Sarsa（六、5，14.2.3）

3. DQN（14.2.4）[paper](./reading/Playing Atati with Deep Reinforcement Learning.pdf)

4. Nature DQN 论文  [paper](./reading/Human-level Control Through Deep Reinforcement Learning.pdf)

5. Double DQN (DDQN)  [paper](./reading/Deep_Reinforcement_Learning_with_Double_Q-learning.pdf)

## 基于策略函数的强化学习

1. PG (十三、3，14.3)  [paper](./reading/Policy_Gradient_Methods_for_Reinforcement_Learning.pdf)

   基于策略方法的提出

   PG目标函数的优化

2. reinforce算法（十三、4，14.3.1）[paper](./reading/Simple statistical gradientfollowing algorithms for connectionist reinforcement learning.pdf)

3. 带基线的reinforce算法（十三、5，14.3.2）

4. DPG [paper](./reading/Deterministic Policy Gradient Algorithms.pdf)

5. DDPG  [paper](./reading/DDPG-Continuous control with deep reinforcement learning.pdf)

## 基于AC框架的强化学习

1. AC (十三、6,14.4)  [paper](./reading/Policy_Gradient_Methods_for_Reinforcement_Learning.pdf)
2. A2C  [intro](https://openai.com/blog/baselines-acktr-a2c/)
3. A3C  [paper](./Asynchronous Methods for Deep Reinforcement Learning.pdf)
4. 实验  [grid world](./reading/A2C-GridWorld-main)

![image-20210722183342729](C:\Users\yinnan\AppData\Roaming\Typora\typora-user-images\image-20210722183342729.png)





